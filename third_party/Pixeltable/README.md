<img src="https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/source/data/pixeltable-logo-large.png" alt="Pixeltable" width="30%" />

## Data infrastructure providing a declarative, incremental approach for multimodal AI.

[Installation](https://pixeltable.github.io/pixeltable/getting-started/) | [Documentation](https://pixeltable.readme.io/) | [API Reference](https://pixeltable.github.io/pixeltable/) | [Code Samples](https://github.com/pixeltable/pixeltable?tab=readme-ov-file#-code-samples) | [Computer Vision](https://docs.pixeltable.com/docs/object-detection-in-videos) | [LLM](https://docs.pixeltable.com/docs/document-indexing-and-rag)

---

This example demonstrates how to use [Pixeltable](https://github.com/pixeltable/pixeltable) with Mistral AI models for efficient prompt engineering and model comparison.

A [Hugging Face Space](https://huggingface.co/spaces/Pixeltable/Prompt-Engineering-and-LLM-Studio) expanding on this use case is available with `open-mistral-nemo` and `mistral-medium`

## Installation

```bash
pip install pixeltable mistralai
```

See how to work with [Mistral AI in Pixeltable](https://docs.pixeltable.com/docs/mistral-ai)
